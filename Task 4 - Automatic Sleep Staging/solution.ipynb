{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 4 - Sleep Staging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this task we will perform sequence classification. We will categorize temporally coherent and uniformly distributed short sections of a long time-series. In particular, for each 4 seconds of a lengthy EEG/EMG measurement of brain activity recorded during sleep, we will assign one of the 3 classes corresponding to the sleep stage present within the evaluated epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import balanced_accuracy_score, confusion_matrix\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, LSTM, GRU\n",
    "from keras.losses import CategoricalCrossentropy\n",
    "from keras import backend as K\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_eeg1 = pd.read_csv(\"train_eeg1.csv\", index_col='Id')\n",
    "train_eeg2 = pd.read_csv(\"train_eeg2.csv\", index_col='Id')\n",
    "train_emg = pd.read_csv(\"train_emg.csv\", index_col='Id')\n",
    "y_train = pd.read_csv(\"train_labels.csv\", index_col='Id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>x10</th>\n",
       "      <th>...</th>\n",
       "      <th>x503</th>\n",
       "      <th>x504</th>\n",
       "      <th>x505</th>\n",
       "      <th>x506</th>\n",
       "      <th>x507</th>\n",
       "      <th>x508</th>\n",
       "      <th>x509</th>\n",
       "      <th>x510</th>\n",
       "      <th>x511</th>\n",
       "      <th>x512</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>64800.000000</td>\n",
       "      <td>64800.000000</td>\n",
       "      <td>64800.000000</td>\n",
       "      <td>64800.000000</td>\n",
       "      <td>64800.000000</td>\n",
       "      <td>64800.000000</td>\n",
       "      <td>64800.000000</td>\n",
       "      <td>64800.000000</td>\n",
       "      <td>64800.000000</td>\n",
       "      <td>64800.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>64800.000000</td>\n",
       "      <td>64800.000000</td>\n",
       "      <td>64800.000000</td>\n",
       "      <td>64800.000000</td>\n",
       "      <td>64800.000000</td>\n",
       "      <td>64800.000000</td>\n",
       "      <td>64800.000000</td>\n",
       "      <td>64800.000000</td>\n",
       "      <td>64800.000000</td>\n",
       "      <td>64800.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.000032</td>\n",
       "      <td>-0.000030</td>\n",
       "      <td>-0.000030</td>\n",
       "      <td>-0.000030</td>\n",
       "      <td>-0.000029</td>\n",
       "      <td>-0.000029</td>\n",
       "      <td>-0.000031</td>\n",
       "      <td>-0.000031</td>\n",
       "      <td>-0.000032</td>\n",
       "      <td>-0.000033</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000034</td>\n",
       "      <td>-0.000034</td>\n",
       "      <td>-0.000034</td>\n",
       "      <td>-0.000034</td>\n",
       "      <td>-0.000034</td>\n",
       "      <td>-0.000033</td>\n",
       "      <td>-0.000032</td>\n",
       "      <td>-0.000033</td>\n",
       "      <td>-0.000033</td>\n",
       "      <td>-0.000032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.000497</td>\n",
       "      <td>0.000496</td>\n",
       "      <td>0.000496</td>\n",
       "      <td>0.000496</td>\n",
       "      <td>0.000497</td>\n",
       "      <td>0.000498</td>\n",
       "      <td>0.000497</td>\n",
       "      <td>0.000498</td>\n",
       "      <td>0.000498</td>\n",
       "      <td>0.000497</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000499</td>\n",
       "      <td>0.000499</td>\n",
       "      <td>0.000499</td>\n",
       "      <td>0.000499</td>\n",
       "      <td>0.000499</td>\n",
       "      <td>0.000498</td>\n",
       "      <td>0.000498</td>\n",
       "      <td>0.000497</td>\n",
       "      <td>0.000498</td>\n",
       "      <td>0.000498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.002500</td>\n",
       "      <td>-0.002700</td>\n",
       "      <td>-0.002400</td>\n",
       "      <td>-0.002400</td>\n",
       "      <td>-0.002500</td>\n",
       "      <td>-0.002400</td>\n",
       "      <td>-0.002300</td>\n",
       "      <td>-0.002400</td>\n",
       "      <td>-0.002800</td>\n",
       "      <td>-0.002600</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002900</td>\n",
       "      <td>-0.002800</td>\n",
       "      <td>-0.002800</td>\n",
       "      <td>-0.002600</td>\n",
       "      <td>-0.002600</td>\n",
       "      <td>-0.002700</td>\n",
       "      <td>-0.002800</td>\n",
       "      <td>-0.002700</td>\n",
       "      <td>-0.003200</td>\n",
       "      <td>-0.002900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.000350</td>\n",
       "      <td>-0.000350</td>\n",
       "      <td>-0.000350</td>\n",
       "      <td>-0.000350</td>\n",
       "      <td>-0.000350</td>\n",
       "      <td>-0.000350</td>\n",
       "      <td>-0.000350</td>\n",
       "      <td>-0.000350</td>\n",
       "      <td>-0.000350</td>\n",
       "      <td>-0.000350</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000360</td>\n",
       "      <td>-0.000350</td>\n",
       "      <td>-0.000360</td>\n",
       "      <td>-0.000360</td>\n",
       "      <td>-0.000360</td>\n",
       "      <td>-0.000350</td>\n",
       "      <td>-0.000360</td>\n",
       "      <td>-0.000350</td>\n",
       "      <td>-0.000360</td>\n",
       "      <td>-0.000350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-0.000034</td>\n",
       "      <td>-0.000035</td>\n",
       "      <td>-0.000036</td>\n",
       "      <td>-0.000036</td>\n",
       "      <td>-0.000031</td>\n",
       "      <td>-0.000033</td>\n",
       "      <td>-0.000039</td>\n",
       "      <td>-0.000039</td>\n",
       "      <td>-0.000038</td>\n",
       "      <td>-0.000038</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000040</td>\n",
       "      <td>-0.000040</td>\n",
       "      <td>-0.000038</td>\n",
       "      <td>-0.000039</td>\n",
       "      <td>-0.000041</td>\n",
       "      <td>-0.000038</td>\n",
       "      <td>-0.000036</td>\n",
       "      <td>-0.000039</td>\n",
       "      <td>-0.000038</td>\n",
       "      <td>-0.000038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000280</td>\n",
       "      <td>0.000280</td>\n",
       "      <td>0.000280</td>\n",
       "      <td>0.000280</td>\n",
       "      <td>0.000280</td>\n",
       "      <td>0.000280</td>\n",
       "      <td>0.000280</td>\n",
       "      <td>0.000280</td>\n",
       "      <td>0.000280</td>\n",
       "      <td>0.000280</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000280</td>\n",
       "      <td>0.000280</td>\n",
       "      <td>0.000280</td>\n",
       "      <td>0.000280</td>\n",
       "      <td>0.000280</td>\n",
       "      <td>0.000280</td>\n",
       "      <td>0.000280</td>\n",
       "      <td>0.000280</td>\n",
       "      <td>0.000280</td>\n",
       "      <td>0.000280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.003300</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>0.002700</td>\n",
       "      <td>0.003100</td>\n",
       "      <td>0.003100</td>\n",
       "      <td>0.002900</td>\n",
       "      <td>0.002900</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>0.002700</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002700</td>\n",
       "      <td>0.002900</td>\n",
       "      <td>0.002600</td>\n",
       "      <td>0.002600</td>\n",
       "      <td>0.002900</td>\n",
       "      <td>0.002900</td>\n",
       "      <td>0.002800</td>\n",
       "      <td>0.003100</td>\n",
       "      <td>0.002900</td>\n",
       "      <td>0.003100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 512 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 x1            x2            x3            x4            x5  \\\n",
       "count  64800.000000  64800.000000  64800.000000  64800.000000  64800.000000   \n",
       "mean      -0.000032     -0.000030     -0.000030     -0.000030     -0.000029   \n",
       "std        0.000497      0.000496      0.000496      0.000496      0.000497   \n",
       "min       -0.002500     -0.002700     -0.002400     -0.002400     -0.002500   \n",
       "25%       -0.000350     -0.000350     -0.000350     -0.000350     -0.000350   \n",
       "50%       -0.000034     -0.000035     -0.000036     -0.000036     -0.000031   \n",
       "75%        0.000280      0.000280      0.000280      0.000280      0.000280   \n",
       "max        0.003300      0.003300      0.002700      0.003100      0.003100   \n",
       "\n",
       "                 x6            x7            x8            x9           x10  \\\n",
       "count  64800.000000  64800.000000  64800.000000  64800.000000  64800.000000   \n",
       "mean      -0.000029     -0.000031     -0.000031     -0.000032     -0.000033   \n",
       "std        0.000498      0.000497      0.000498      0.000498      0.000497   \n",
       "min       -0.002400     -0.002300     -0.002400     -0.002800     -0.002600   \n",
       "25%       -0.000350     -0.000350     -0.000350     -0.000350     -0.000350   \n",
       "50%       -0.000033     -0.000039     -0.000039     -0.000038     -0.000038   \n",
       "75%        0.000280      0.000280      0.000280      0.000280      0.000280   \n",
       "max        0.002900      0.002900      0.002500      0.002700      0.003000   \n",
       "\n",
       "       ...          x503          x504          x505          x506  \\\n",
       "count  ...  64800.000000  64800.000000  64800.000000  64800.000000   \n",
       "mean   ...     -0.000034     -0.000034     -0.000034     -0.000034   \n",
       "std    ...      0.000499      0.000499      0.000499      0.000499   \n",
       "min    ...     -0.002900     -0.002800     -0.002800     -0.002600   \n",
       "25%    ...     -0.000360     -0.000350     -0.000360     -0.000360   \n",
       "50%    ...     -0.000040     -0.000040     -0.000038     -0.000039   \n",
       "75%    ...      0.000280      0.000280      0.000280      0.000280   \n",
       "max    ...      0.002700      0.002900      0.002600      0.002600   \n",
       "\n",
       "               x507          x508          x509          x510          x511  \\\n",
       "count  64800.000000  64800.000000  64800.000000  64800.000000  64800.000000   \n",
       "mean      -0.000034     -0.000033     -0.000032     -0.000033     -0.000033   \n",
       "std        0.000499      0.000498      0.000498      0.000497      0.000498   \n",
       "min       -0.002600     -0.002700     -0.002800     -0.002700     -0.003200   \n",
       "25%       -0.000360     -0.000350     -0.000360     -0.000350     -0.000360   \n",
       "50%       -0.000041     -0.000038     -0.000036     -0.000039     -0.000038   \n",
       "75%        0.000280      0.000280      0.000280      0.000280      0.000280   \n",
       "max        0.002900      0.002900      0.002800      0.003100      0.002900   \n",
       "\n",
       "               x512  \n",
       "count  64800.000000  \n",
       "mean      -0.000032  \n",
       "std        0.000498  \n",
       "min       -0.002900  \n",
       "25%       -0.000350  \n",
       "50%       -0.000038  \n",
       "75%        0.000280  \n",
       "max        0.003100  \n",
       "\n",
       "[8 rows x 512 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_eeg1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>x10</th>\n",
       "      <th>...</th>\n",
       "      <th>x503</th>\n",
       "      <th>x504</th>\n",
       "      <th>x505</th>\n",
       "      <th>x506</th>\n",
       "      <th>x507</th>\n",
       "      <th>x508</th>\n",
       "      <th>x509</th>\n",
       "      <th>x510</th>\n",
       "      <th>x511</th>\n",
       "      <th>x512</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>64800.000000</td>\n",
       "      <td>64800.000000</td>\n",
       "      <td>64800.000000</td>\n",
       "      <td>64800.000000</td>\n",
       "      <td>64800.000000</td>\n",
       "      <td>64800.000000</td>\n",
       "      <td>64800.000000</td>\n",
       "      <td>64800.000000</td>\n",
       "      <td>64800.000000</td>\n",
       "      <td>64800.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>64800.000000</td>\n",
       "      <td>64800.000000</td>\n",
       "      <td>64800.000000</td>\n",
       "      <td>64800.000000</td>\n",
       "      <td>64800.000000</td>\n",
       "      <td>64800.000000</td>\n",
       "      <td>64800.000000</td>\n",
       "      <td>64800.000000</td>\n",
       "      <td>64800.000000</td>\n",
       "      <td>64800.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.000038</td>\n",
       "      <td>-0.000036</td>\n",
       "      <td>-0.000038</td>\n",
       "      <td>-0.000038</td>\n",
       "      <td>-0.000038</td>\n",
       "      <td>-0.000037</td>\n",
       "      <td>-0.000038</td>\n",
       "      <td>-0.000038</td>\n",
       "      <td>-0.000039</td>\n",
       "      <td>-0.000039</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000043</td>\n",
       "      <td>-0.000043</td>\n",
       "      <td>-0.000043</td>\n",
       "      <td>-0.000044</td>\n",
       "      <td>-0.000042</td>\n",
       "      <td>-0.000040</td>\n",
       "      <td>-0.000040</td>\n",
       "      <td>-0.000039</td>\n",
       "      <td>-0.000039</td>\n",
       "      <td>-0.000039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.000470</td>\n",
       "      <td>0.000469</td>\n",
       "      <td>0.000468</td>\n",
       "      <td>0.000467</td>\n",
       "      <td>0.000469</td>\n",
       "      <td>0.000470</td>\n",
       "      <td>0.000470</td>\n",
       "      <td>0.000469</td>\n",
       "      <td>0.000470</td>\n",
       "      <td>0.000469</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000470</td>\n",
       "      <td>0.000469</td>\n",
       "      <td>0.000469</td>\n",
       "      <td>0.000469</td>\n",
       "      <td>0.000469</td>\n",
       "      <td>0.000469</td>\n",
       "      <td>0.000470</td>\n",
       "      <td>0.000469</td>\n",
       "      <td>0.000469</td>\n",
       "      <td>0.000469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.002900</td>\n",
       "      <td>-0.002500</td>\n",
       "      <td>-0.002500</td>\n",
       "      <td>-0.002700</td>\n",
       "      <td>-0.002600</td>\n",
       "      <td>-0.002500</td>\n",
       "      <td>-0.002700</td>\n",
       "      <td>-0.002500</td>\n",
       "      <td>-0.002700</td>\n",
       "      <td>-0.002600</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003000</td>\n",
       "      <td>-0.003000</td>\n",
       "      <td>-0.002800</td>\n",
       "      <td>-0.002600</td>\n",
       "      <td>-0.002600</td>\n",
       "      <td>-0.002500</td>\n",
       "      <td>-0.002600</td>\n",
       "      <td>-0.002500</td>\n",
       "      <td>-0.002800</td>\n",
       "      <td>-0.003000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.000330</td>\n",
       "      <td>-0.000330</td>\n",
       "      <td>-0.000330</td>\n",
       "      <td>-0.000320</td>\n",
       "      <td>-0.000330</td>\n",
       "      <td>-0.000330</td>\n",
       "      <td>-0.000330</td>\n",
       "      <td>-0.000330</td>\n",
       "      <td>-0.000330</td>\n",
       "      <td>-0.000330</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000330</td>\n",
       "      <td>-0.000330</td>\n",
       "      <td>-0.000340</td>\n",
       "      <td>-0.000340</td>\n",
       "      <td>-0.000340</td>\n",
       "      <td>-0.000330</td>\n",
       "      <td>-0.000330</td>\n",
       "      <td>-0.000340</td>\n",
       "      <td>-0.000330</td>\n",
       "      <td>-0.000330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-0.000043</td>\n",
       "      <td>-0.000044</td>\n",
       "      <td>-0.000044</td>\n",
       "      <td>-0.000043</td>\n",
       "      <td>-0.000043</td>\n",
       "      <td>-0.000043</td>\n",
       "      <td>-0.000045</td>\n",
       "      <td>-0.000043</td>\n",
       "      <td>-0.000045</td>\n",
       "      <td>-0.000043</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000049</td>\n",
       "      <td>-0.000048</td>\n",
       "      <td>-0.000047</td>\n",
       "      <td>-0.000047</td>\n",
       "      <td>-0.000047</td>\n",
       "      <td>-0.000043</td>\n",
       "      <td>-0.000044</td>\n",
       "      <td>-0.000043</td>\n",
       "      <td>-0.000043</td>\n",
       "      <td>-0.000043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000250</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>0.000240</td>\n",
       "      <td>0.000240</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000240</td>\n",
       "      <td>0.000240</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>0.000250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.003300</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003100</td>\n",
       "      <td>0.002900</td>\n",
       "      <td>0.002800</td>\n",
       "      <td>0.002700</td>\n",
       "      <td>0.002700</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>0.003300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 512 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 x1            x2            x3            x4            x5  \\\n",
       "count  64800.000000  64800.000000  64800.000000  64800.000000  64800.000000   \n",
       "mean      -0.000038     -0.000036     -0.000038     -0.000038     -0.000038   \n",
       "std        0.000470      0.000469      0.000468      0.000467      0.000469   \n",
       "min       -0.002900     -0.002500     -0.002500     -0.002700     -0.002600   \n",
       "25%       -0.000330     -0.000330     -0.000330     -0.000320     -0.000330   \n",
       "50%       -0.000043     -0.000044     -0.000044     -0.000043     -0.000043   \n",
       "75%        0.000250      0.000250      0.000240      0.000240      0.000250   \n",
       "max        0.003300      0.003300      0.003300      0.003300      0.003300   \n",
       "\n",
       "                 x6            x7            x8            x9           x10  \\\n",
       "count  64800.000000  64800.000000  64800.000000  64800.000000  64800.000000   \n",
       "mean      -0.000037     -0.000038     -0.000038     -0.000039     -0.000039   \n",
       "std        0.000470      0.000470      0.000469      0.000470      0.000469   \n",
       "min       -0.002500     -0.002700     -0.002500     -0.002700     -0.002600   \n",
       "25%       -0.000330     -0.000330     -0.000330     -0.000330     -0.000330   \n",
       "50%       -0.000043     -0.000045     -0.000043     -0.000045     -0.000043   \n",
       "75%        0.000250      0.000250      0.000250      0.000250      0.000250   \n",
       "max        0.003300      0.003300      0.003300      0.003300      0.003300   \n",
       "\n",
       "       ...          x503          x504          x505          x506  \\\n",
       "count  ...  64800.000000  64800.000000  64800.000000  64800.000000   \n",
       "mean   ...     -0.000043     -0.000043     -0.000043     -0.000044   \n",
       "std    ...      0.000470      0.000469      0.000469      0.000469   \n",
       "min    ...     -0.003000     -0.003000     -0.002800     -0.002600   \n",
       "25%    ...     -0.000330     -0.000330     -0.000340     -0.000340   \n",
       "50%    ...     -0.000049     -0.000048     -0.000047     -0.000047   \n",
       "75%    ...      0.000240      0.000240      0.000250      0.000250   \n",
       "max    ...      0.003100      0.002900      0.002800      0.002700   \n",
       "\n",
       "               x507          x508          x509          x510          x511  \\\n",
       "count  64800.000000  64800.000000  64800.000000  64800.000000  64800.000000   \n",
       "mean      -0.000042     -0.000040     -0.000040     -0.000039     -0.000039   \n",
       "std        0.000469      0.000469      0.000470      0.000469      0.000469   \n",
       "min       -0.002600     -0.002500     -0.002600     -0.002500     -0.002800   \n",
       "25%       -0.000340     -0.000330     -0.000330     -0.000340     -0.000330   \n",
       "50%       -0.000047     -0.000043     -0.000044     -0.000043     -0.000043   \n",
       "75%        0.000250      0.000250      0.000250      0.000250      0.000250   \n",
       "max        0.002700      0.003000      0.003200      0.003300      0.003300   \n",
       "\n",
       "               x512  \n",
       "count  64800.000000  \n",
       "mean      -0.000039  \n",
       "std        0.000469  \n",
       "min       -0.003000  \n",
       "25%       -0.000330  \n",
       "50%       -0.000043  \n",
       "75%        0.000250  \n",
       "max        0.003300  \n",
       "\n",
       "[8 rows x 512 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_eeg2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>x10</th>\n",
       "      <th>...</th>\n",
       "      <th>x503</th>\n",
       "      <th>x504</th>\n",
       "      <th>x505</th>\n",
       "      <th>x506</th>\n",
       "      <th>x507</th>\n",
       "      <th>x508</th>\n",
       "      <th>x509</th>\n",
       "      <th>x510</th>\n",
       "      <th>x511</th>\n",
       "      <th>x512</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>64800.000000</td>\n",
       "      <td>64800.000000</td>\n",
       "      <td>64800.000000</td>\n",
       "      <td>64800.000000</td>\n",
       "      <td>64800.000000</td>\n",
       "      <td>64800.000000</td>\n",
       "      <td>64800.000000</td>\n",
       "      <td>64800.000000</td>\n",
       "      <td>64800.000000</td>\n",
       "      <td>64800.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>64800.000000</td>\n",
       "      <td>64800.000000</td>\n",
       "      <td>64800.000000</td>\n",
       "      <td>64800.000000</td>\n",
       "      <td>64800.000000</td>\n",
       "      <td>64800.000000</td>\n",
       "      <td>64800.000000</td>\n",
       "      <td>64800.000000</td>\n",
       "      <td>64800.000000</td>\n",
       "      <td>64800.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.000005</td>\n",
       "      <td>-0.000006</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>-0.000006</td>\n",
       "      <td>-0.000006</td>\n",
       "      <td>-0.000006</td>\n",
       "      <td>-0.000006</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>-0.000006</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>-0.000006</td>\n",
       "      <td>-0.000006</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>-0.000006</td>\n",
       "      <td>-0.000006</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>-0.000006</td>\n",
       "      <td>-0.000005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.000112</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>0.000117</td>\n",
       "      <td>0.000116</td>\n",
       "      <td>0.000116</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>0.000116</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>0.000112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.002800</td>\n",
       "      <td>-0.002500</td>\n",
       "      <td>-0.002600</td>\n",
       "      <td>-0.003200</td>\n",
       "      <td>-0.002100</td>\n",
       "      <td>-0.002300</td>\n",
       "      <td>-0.002400</td>\n",
       "      <td>-0.002700</td>\n",
       "      <td>-0.002500</td>\n",
       "      <td>-0.002700</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002700</td>\n",
       "      <td>-0.002200</td>\n",
       "      <td>-0.003300</td>\n",
       "      <td>-0.002300</td>\n",
       "      <td>-0.002300</td>\n",
       "      <td>-0.002600</td>\n",
       "      <td>-0.002300</td>\n",
       "      <td>-0.002400</td>\n",
       "      <td>-0.002300</td>\n",
       "      <td>-0.001900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.000026</td>\n",
       "      <td>-0.000027</td>\n",
       "      <td>-0.000026</td>\n",
       "      <td>-0.000027</td>\n",
       "      <td>-0.000027</td>\n",
       "      <td>-0.000027</td>\n",
       "      <td>-0.000027</td>\n",
       "      <td>-0.000027</td>\n",
       "      <td>-0.000026</td>\n",
       "      <td>-0.000027</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000026</td>\n",
       "      <td>-0.000026</td>\n",
       "      <td>-0.000027</td>\n",
       "      <td>-0.000026</td>\n",
       "      <td>-0.000026</td>\n",
       "      <td>-0.000027</td>\n",
       "      <td>-0.000027</td>\n",
       "      <td>-0.000026</td>\n",
       "      <td>-0.000027</td>\n",
       "      <td>-0.000026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-0.000005</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>-0.000005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.003300</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>0.003300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 512 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 x1            x2            x3            x4            x5  \\\n",
       "count  64800.000000  64800.000000  64800.000000  64800.000000  64800.000000   \n",
       "mean      -0.000005     -0.000006     -0.000005     -0.000005     -0.000006   \n",
       "std        0.000112      0.000113      0.000114      0.000114      0.000115   \n",
       "min       -0.002800     -0.002500     -0.002600     -0.003200     -0.002100   \n",
       "25%       -0.000026     -0.000027     -0.000026     -0.000027     -0.000027   \n",
       "50%       -0.000005     -0.000005     -0.000005     -0.000005     -0.000005   \n",
       "75%        0.000014      0.000014      0.000014      0.000014      0.000014   \n",
       "max        0.003300      0.003300      0.003300      0.003300      0.003300   \n",
       "\n",
       "                 x6            x7            x8            x9           x10  \\\n",
       "count  64800.000000  64800.000000  64800.000000  64800.000000  64800.000000   \n",
       "mean      -0.000006     -0.000006     -0.000006     -0.000005     -0.000006   \n",
       "std        0.000113      0.000117      0.000116      0.000116      0.000115   \n",
       "min       -0.002300     -0.002400     -0.002700     -0.002500     -0.002700   \n",
       "25%       -0.000027     -0.000027     -0.000027     -0.000026     -0.000027   \n",
       "50%       -0.000005     -0.000005     -0.000005     -0.000005     -0.000005   \n",
       "75%        0.000014      0.000014      0.000014      0.000015      0.000014   \n",
       "max        0.003300      0.003300      0.003300      0.003300      0.003300   \n",
       "\n",
       "       ...          x503          x504          x505          x506  \\\n",
       "count  ...  64800.000000  64800.000000  64800.000000  64800.000000   \n",
       "mean   ...     -0.000005     -0.000006     -0.000006     -0.000005   \n",
       "std    ...      0.000114      0.000113      0.000116      0.000114   \n",
       "min    ...     -0.002700     -0.002200     -0.003300     -0.002300   \n",
       "25%    ...     -0.000026     -0.000026     -0.000027     -0.000026   \n",
       "50%    ...     -0.000005     -0.000005     -0.000005     -0.000005   \n",
       "75%    ...      0.000014      0.000014      0.000014      0.000014   \n",
       "max    ...      0.003300      0.003300      0.003300      0.003300   \n",
       "\n",
       "               x507          x508          x509          x510          x511  \\\n",
       "count  64800.000000  64800.000000  64800.000000  64800.000000  64800.000000   \n",
       "mean      -0.000005     -0.000006     -0.000006     -0.000005     -0.000006   \n",
       "std        0.000113      0.000115      0.000115      0.000113      0.000113   \n",
       "min       -0.002300     -0.002600     -0.002300     -0.002400     -0.002300   \n",
       "25%       -0.000026     -0.000027     -0.000027     -0.000026     -0.000027   \n",
       "50%       -0.000005     -0.000005     -0.000005     -0.000005     -0.000005   \n",
       "75%        0.000014      0.000014      0.000014      0.000014      0.000014   \n",
       "max        0.003300      0.003300      0.003300      0.003300      0.003300   \n",
       "\n",
       "               x512  \n",
       "count  64800.000000  \n",
       "mean      -0.000005  \n",
       "std        0.000112  \n",
       "min       -0.001900  \n",
       "25%       -0.000026  \n",
       "50%       -0.000005  \n",
       "75%        0.000015  \n",
       "max        0.003300  \n",
       "\n",
       "[8 rows x 512 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_emg.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 34114\n",
      "2 27133\n",
      "3 3553\n"
     ]
    }
   ],
   "source": [
    "# print class frequencies, used later for weighted categorical crossentropy\n",
    "print(1, np.sum(y_train['y']==1))\n",
    "print(2, np.sum(y_train['y']==2))\n",
    "print(3, np.sum(y_train['y']==3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define necessary functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def features(data):\n",
    "    \"\"\"Fourier features used for EEG\"\"\"\n",
    "    \n",
    "    # sampling rate (128 Hz)\n",
    "    fs = 128 \n",
    "\n",
    "    # define EEG bands\n",
    "    eeg_bands = {'Delta': (0, 4),\n",
    "                 'Theta': (4, 8),\n",
    "                 'Alpha': (8, 12),\n",
    "                 'Beta': (12, 30),\n",
    "                 'Gamma': (30, 1000)}\n",
    "    \n",
    "    # initialize output\n",
    "    eeg_band_fft = np.empty((data.shape[0],len(eeg_bands.keys())))\n",
    "    \n",
    "    for i in range(data.shape[0]):\n",
    "\n",
    "        # get real amplitudes of FFT (only in postive frequencies)\n",
    "        fft_vals = np.absolute(np.fft.rfft(data.loc[i,:]))\n",
    "\n",
    "        # get frequencies for amplitudes in Hz\n",
    "        fft_freq = np.fft.rfftfreq(len(data.loc[i,:]), 1.0/fs)\n",
    "\n",
    "        # take the mean of the fft amplitude for each EEG band\n",
    "        for band_idx, band in enumerate(eeg_bands):  \n",
    "            freq_ix = np.where((fft_freq >= eeg_bands[band][0]) & (fft_freq <= eeg_bands[band][1]))[0]\n",
    "            eeg_band_fft[i,band_idx] = np.mean(fft_vals[freq_ix])\n",
    "        \n",
    "        #if int(i/5000)==i/5000: print(i)\n",
    "            \n",
    "    return eeg_band_fft\n",
    "\n",
    "def energy_signal(data):\n",
    "    energy = np.empty((data.shape[0], 1))\n",
    "    for i in range(data.shape[0]):\n",
    "        energy[i] = np.sum(np.abs(data.loc[i, :])**2)\n",
    "    \n",
    "    return energy\n",
    "\n",
    "\n",
    "def concatenate_signals(x_train1, x_train2, x_train3):\n",
    "    output = features(x_train1)\n",
    "    output = np.append(output, features(x_train2), axis=1)\n",
    "    output = np.append(output, energy_signal(x_train3), axis=1)\n",
    "    return output\n",
    "\n",
    "\n",
    "def plot(data, title):\n",
    "    means = []\n",
    "    for i in range(5):\n",
    "        means.append(np.mean(data[:,i]))\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_axes([0,0,1,1])\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel('Bands')\n",
    "    ax.set_ylabel('Mean band amplitude')\n",
    "    vals = ['Delta', 'Theta', 'Alpha', 'Beta', 'Gamma']\n",
    "    colors = ['r', 'b', 'g', 'y', 'c']\n",
    "    barlist = ax.bar(vals, means)\n",
    "    for i in range(5):\n",
    "        barlist[i].set_color(colors[i])\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def create_dataset(X, Y=None, look_back=6):\n",
    "    dataX = np.empty((X.shape[0]-2*look_back, 2*look_back, X.shape[1]))\n",
    "    if Y is None:\n",
    "        dataY = None\n",
    "    else:\n",
    "        dataY = np.empty((Y.shape[0]-2*look_back, Y.shape[1]))\n",
    "    for i in range(X.shape[0]-2*look_back):\n",
    "        dataX[i,:,:] = X[i:(i+2*look_back), :]\n",
    "        if dataY is not None: dataY[i,:] = Y[i+look_back, :].toarray()\n",
    "    return dataX, dataY\n",
    "\n",
    "\n",
    "def weighted_categorical_crossentropy(weights):\n",
    "    \"\"\"\n",
    "    A weighted version of keras.objectives.categorical_crossentropy\n",
    "    \n",
    "    Variables:\n",
    "        weights: numpy array of shape (C,) where C is the number of classes\n",
    "    \n",
    "    Usage:\n",
    "        weights = np.array([0.5,2,10]) # Class one at 0.5, class 2 twice the normal weights, class 3 10x.\n",
    "        loss = weighted_categorical_crossentropy(weights)\n",
    "        model.compile(loss=loss,optimizer='adam')\n",
    "    \"\"\"\n",
    "    \n",
    "    weights = K.variable(weights)\n",
    "        \n",
    "    def loss(y_true, y_pred):\n",
    "        # scale predictions so that the class probas of each sample sum to 1\n",
    "        y_pred /= K.sum(y_pred, axis=-1, keepdims=True)\n",
    "        # clip to prevent NaN's and Inf's\n",
    "        y_pred = K.clip(y_pred, K.epsilon(), 1 - K.epsilon())\n",
    "        # calc\n",
    "        loss = y_true * K.log(y_pred) * weights\n",
    "        loss = -K.sum(loss, -1)\n",
    "        return loss\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot(features(train_eeg1), 'EEG1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = concatenate_signals(train_eeg1, train_eeg2, train_emg)\n",
    "x_train.shape\n",
    "# on-hot-encode y\n",
    "enc = OneHotEncoder().fit(np.array(y_train).reshape(-1, 1))\n",
    "y_train_oh = enc.transform(np.array(y_train).reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "look_back = 6\n",
    "subject_size = 21600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# leave-one-out\n",
    "x_trn1, y_trn1 = create_dataset(x_train[0:subject_size, :], y_train_oh[0:subject_size,:], look_back)\n",
    "x_trn2, y_trn2 = create_dataset(x_train[subject_size+1:2*subject_size, :], y_train_oh[subject_size+1:2*subject_size,:], look_back)\n",
    "x_val,  y_val  = create_dataset(x_train[2*subject_size+1:3*subject_size,:], y_train_oh[2*subject_size+1:3*subject_size,:], look_back)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_trn = np.append(x_trn1, x_trn2, axis=0)\n",
    "y_trn = np.append(y_trn1, y_trn2, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_4 (LSTM)                (None, 12, 25)            3700      \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, 30)                6720      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 93        \n",
      "=================================================================\n",
      "Total params: 10,513\n",
      "Trainable params: 10,513\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# LSTM definition\n",
    "model_lstm = Sequential()\n",
    "model_lstm.add(LSTM(25, return_sequences=True,input_shape=(x_trn.shape[1], x_trn.shape[2])))\n",
    "model_lstm.add(LSTM(units=30))\n",
    "model_lstm.add(Dense(3, activation='softmax')) \n",
    "model_lstm.compile(loss=weighted_categorical_crossentropy(np.array([1/3.4114, 1/2.7133, 1/0.3553])), optimizer='adam')\n",
    "model_lstm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "675/675 [==============================] - 10s 10ms/step - loss: 5.1734e-05 - val_loss: 4.5814e-05\n",
      "Epoch 2/15\n",
      "675/675 [==============================] - 6s 9ms/step - loss: 5.1701e-05 - val_loss: 4.1250e-05\n",
      "Epoch 3/15\n",
      "675/675 [==============================] - 7s 10ms/step - loss: 4.2922e-05 - val_loss: 4.8145e-05\n",
      "Epoch 4/15\n",
      "675/675 [==============================] - 7s 10ms/step - loss: 3.8715e-05 - val_loss: 4.5113e-05\n",
      "Epoch 5/15\n",
      "675/675 [==============================] - 7s 10ms/step - loss: 3.3355e-05 - val_loss: 4.8040e-05\n",
      "Epoch 6/15\n",
      "675/675 [==============================] - 8s 12ms/step - loss: 2.7820e-05 - val_loss: 5.3104e-05\n",
      "Epoch 7/15\n",
      "675/675 [==============================] - 7s 10ms/step - loss: 2.5091e-05 - val_loss: 5.5449e-05\n",
      "Epoch 8/15\n",
      "675/675 [==============================] - 7s 10ms/step - loss: 2.3365e-05 - val_loss: 5.5826e-05\n",
      "Epoch 9/15\n",
      "675/675 [==============================] - 7s 10ms/step - loss: 2.1985e-05 - val_loss: 5.3849e-05\n",
      "Epoch 10/15\n",
      "675/675 [==============================] - 6s 10ms/step - loss: 2.0619e-05 - val_loss: 5.1467e-05\n",
      "Epoch 11/15\n",
      "675/675 [==============================] - 6s 10ms/step - loss: 1.9409e-05 - val_loss: 4.9703e-05\n",
      "Epoch 12/15\n",
      "675/675 [==============================] - 7s 10ms/step - loss: 1.8497e-05 - val_loss: 4.9911e-05\n",
      "Epoch 13/15\n",
      "675/675 [==============================] - 7s 10ms/step - loss: 1.7846e-05 - val_loss: 5.0619e-05\n",
      "Epoch 14/15\n",
      "675/675 [==============================] - 7s 10ms/step - loss: 1.7368e-05 - val_loss: 4.6682e-05\n",
      "Epoch 15/15\n",
      "675/675 [==============================] - 7s 10ms/step - loss: 1.6635e-05 - val_loss: 3.5947e-05\n"
     ]
    }
   ],
   "source": [
    "# Fit\n",
    "history = model_lstm.fit(x_trn, y_trn, epochs=15, batch_size=64, validation_data=(x_val, y_val),  shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced accuracy score:  0.7561438126071556\n",
      "Confusion matrix\n",
      " [[8231   17 2771]\n",
      " [3920 5137  769]\n",
      " [   1    0  741]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate\n",
    "pred_val = model_lstm.predict(x_val)\n",
    "pred_y_val = np.argmax(pred_val, axis=1) + 1\n",
    "true_y_val = np.argmax(y_val, axis=1) + 1\n",
    "print(\"Balanced accuracy score: \", balanced_accuracy_score(true_y_val, pred_y_val))\n",
    "print(\"Confusion matrix\\n\", confusion_matrix(true_y_val, pred_y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test1 = pd.read_csv(\"test_eeg1.csv\", index_col='Id')\n",
    "x_test2 = pd.read_csv(\"test_eeg2.csv\", index_col='Id')\n",
    "x_test3 = pd.read_csv(\"test_emg.csv\", index_col='Id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = concatenate_signals(x_test1, x_test2, x_test3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tst, _ = create_dataset(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict\n",
    "pred_tst = model_lstm.predict(x_tst)\n",
    "pred_y_tst = np.argmax(pred_tst, axis=1) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lookback\n",
    "solution = np.empty(x_test.shape[0])\n",
    "solution[range(look_back,x_test.shape[0] - look_back)] = pred_y_tst\n",
    "# for lookback impute first value and last values\n",
    "solution[range(look_back)] = pred_y_tst[0]\n",
    "solution[range(x_test.shape[0] - look_back,x_test.shape[0])] = pred_y_tst[-1]\n",
    "\n",
    "ids = np.arange(0, len(solution))\n",
    "output = pd.DataFrame({'Id': ids,\n",
    "                           'y': solution})\n",
    "output.to_csv(\"output.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
